import OpenAI from "openai";
import { NextResponse } from "next/server";

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

const DEFAULT_MODEL = process.env.OPENAI_IMAGE_DIFF_MODEL ?? "gpt-5-nano";
const DEFAULT_IMAGE_SIZE = process.env.OPENAI_IMAGE_DIFF_SIZE ?? "1024x1024";

export const runtime = "nodejs";
export const dynamic = "force-dynamic";
export const maxDuration = 60;

type ResponseContentItem = {
  type?: string;
  image_base64?: string;
  b64_json?: string;
  mime_type?: string;
  text?: string;
};

type ResponseOutputBlock = {
  content?: ResponseContentItem[];
};

type DiffResponsePayload = {
  output?: ResponseOutputBlock[];
  output_text?: string;
};

const isFile = (value: unknown): value is File => {
  return typeof File !== "undefined" && value instanceof File;
};

const fileToDataUri = async (file: File) => {
  const arrayBuffer = await file.arrayBuffer();
  const buffer = Buffer.from(arrayBuffer);
  const mime = file.type || "application/octet-stream";
  return {
    dataUri: `data:${mime};base64,${buffer.toString("base64")}`,
    size: buffer.byteLength,
    mime,
  };
};

const extractImageFromResponse = (response: DiffResponsePayload) => {
  const output = response?.output ?? [];
  for (const item of output) {
    const contents = item?.content ?? [];
    for (const content of contents) {
      const type = content?.type;
      if (type === "image" || type === "output_image") {
        const base64 =
          typeof content?.image_base64 === "string"
            ? content.image_base64
            : typeof content?.b64_json === "string"
            ? content.b64_json
            : null;

        if (base64) {
          const mime = typeof content?.mime_type === "string" ? content.mime_type : "image/png";
          return { base64, mime };
        }
      }
    }
  }

  return null;
};

const extractTextualFallback = (response: DiffResponsePayload) => {
  if (typeof response?.output_text === "string" && response.output_text.length > 0) {
    return response.output_text;
  }

  const output = response?.output ?? [];
  for (const item of output) {
    const contents = item?.content ?? [];
    for (const content of contents) {
      const type = content?.type;
      if (type === "output_text" || type === "text") {
        const text = content?.text;
        if (typeof text === "string" && text.length > 0) {
          return text;
        }
      }
    }
  }

  return null;
};

export async function POST(request: Request) {
  if (!process.env.OPENAI_API_KEY) {
    return NextResponse.json(
      { error: "OPENAI_API_KEY is not configured on the server." },
      { status: 500 },
    );
  }

  const formData = await request.formData();
  const first = formData.get("imageA");
  const second = formData.get("imageB");

  if (!isFile(first) || !isFile(second) || first.size === 0 || second.size === 0) {
    return NextResponse.json(
      { error: "Both imageA and imageB files are required." },
      { status: 400 },
    );
  }

  try {
    const [firstImage, secondImage] = await Promise.all([fileToDataUri(first), fileToDataUri(second)]);

    const systemPrompt =
      "You are an assistant that compares two input images and produces a single output image that highlights every meaningful visual difference. " +
      "Overlay annotations, arrows, or color highlights so the resulting image clearly communicates how the two inputs differ. " +
      "Preserve the resolution and orientation of the inputs as much as possible.";

    const response = await openai.responses.create({
      model: DEFAULT_MODEL,
      modalities: ["image"],
      instructions: systemPrompt,
      input: [
        {
          role: "user",
          content: [
            {
              type: "input_text",
              text: "Compare the following two images and generate a composite image that visualizes their differences with clear highlights.",
            },
            {
              type: "input_image",
              image_url: firstImage.dataUri,
            },
            {
              type: "input_image",
              image_url: secondImage.dataUri,
            },
          ],
        },
      ],
      image: {
        size: DEFAULT_IMAGE_SIZE,
      },
    });

    const imageResult = extractImageFromResponse(response);

    if (!imageResult) {
      const analysis = extractTextualFallback(response);

      if (analysis) {
        return NextResponse.json(
          {
            error: "Image diff could not be generated. See textual analysis for details.",
            analysis,
          },
          { status: 502 },
        );
      }

      return NextResponse.json(
        { error: "Image diff could not be generated by the model." },
        { status: 502 },
      );
    }

    return NextResponse.json(
      {
        image: `data:${imageResult.mime};base64,${imageResult.base64}`,
      },
      { status: 200 },
    );
  } catch (error) {
    console.error("OpenAI diff request failed:", error);
    return NextResponse.json(
      {
        error:
          error instanceof OpenAI.APIError
            ? error.message
            : "Unexpected error occurred while generating the diff image.",
      },
      { status: 500 },
    );
  }
}
